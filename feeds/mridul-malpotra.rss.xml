<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NILMTK Blog Update</title><link>/</link><description></description><atom:link href="/feeds/mridul-malpotra.rss.xml" rel="self"></atom:link><lastBuildDate>Wed, 26 Nov 2014 21:25:00 +0100</lastBuildDate><item><title>A summary of NILM-Eval and the ECO Dataset</title><link>/nilm-eval-and-eco-dataset.html</link><description>&lt;p&gt;&lt;a href="https://www.vs.inf.ethz.ch/publ/papers/beckel-2014-nilm.pdf"&gt;Link to the paper&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;A summary on the evaluation of NILM-Eval on certain NILM-Algorithms&lt;/h1&gt;
&lt;p&gt;The paper was focused on primarily demonstrating the &lt;strong&gt;NILM-Eval framework&lt;/strong&gt; alongside their publicly available ECO Dataset on 2 supervised (semi) and 2 unsupervised algorithms. The analysis included defining configurations, testing relevant dataset portions on each algorithm and determining the efficiency and accuracy of each.&lt;/p&gt;
&lt;h3&gt;Algorithms criteria and Evaluation methodology&lt;/h3&gt;
&lt;p&gt;The primary parameters which were considered in NILM-Eval while selecting the algorithms were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Data Granularity:&lt;/strong&gt; ECO Dataset is sampled at 1 Hz. Variations in the algorithms needed to be considered.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learning Methods:&lt;/strong&gt; Supervised  or unsupervised. Considerations on clustering algorithms and Hidden Markov models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information Detail:&lt;/strong&gt; Various parameters data sampled.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bound setting configuration files (default and customized) with multiple dataset parameters for the algorithms implemented in the Framework. Uses MATLAB with multiple instances to scale over. Some parameters measured are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Precision(&lt;strong&gt;PRE&lt;/strong&gt;)(True positives/ All positives)and Recall(&lt;strong&gt;REC&lt;/strong&gt;)(True positives/All true cases) measured.&lt;/li&gt;
&lt;li&gt;Root means square error, deviation for data and switching calculated.&lt;/li&gt;
&lt;li&gt;Calculated &lt;strong&gt;F1&lt;/strong&gt; which is the harmonic mean of the precision and the deviation observed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;ECO Dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Primary focus on Plug data.&lt;/li&gt;
&lt;li&gt;Publicly available dataset of 6 Swiss households.&lt;/li&gt;
&lt;li&gt;8 months duration of Smart meter and plug data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1 Hz&lt;/strong&gt; sampling frequency.&lt;/li&gt;
&lt;li&gt;Measures real and reactive 3-phase power.&lt;/li&gt;
&lt;li&gt;Significant Other portion in dataset owing to the limited plug data sampled.&lt;/li&gt;
&lt;li&gt;Includes occupancy information.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Algorithms&lt;/h2&gt;
&lt;p&gt;Each algorithm was used having frequency input comparable to that of ECO Dataset viz. 1 Hz.&lt;/p&gt;
&lt;h4&gt;Parson's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Uses &lt;strong&gt;Hidden Markov Models (HMM)&lt;/strong&gt;, which are systems consisting of and monitoring memoryless processes with random variables. In HMMs, the states observed are kept secret.&lt;/li&gt;
&lt;li&gt;Uses the &lt;strong&gt;Viterbi algorithm&lt;/strong&gt;, which finds the hidden states observed in the HMMs.&lt;/li&gt;
&lt;li&gt;Finds most probable state transitions and calculates difference in appliance and average consumption. Repeats for others.&lt;/li&gt;
&lt;li&gt;Makes a training model using these &lt;em&gt;semi-supervised&lt;/em&gt; approaches.&lt;/li&gt;
&lt;li&gt;Uses a generic application model for creating the model, unless a specific application model is considered.&lt;/li&gt;
&lt;li&gt;Uses the &lt;strong&gt;REDD Dataset&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Baranski's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Extracts and clusters events into separate entities.&lt;/li&gt;
&lt;li&gt;Uses the &lt;em&gt;Genetic algorithm&lt;/em&gt;, which implements natural selection in the clusters to give most probable application clusters.&lt;/li&gt;
&lt;li&gt;Unsupervised approach followed to cluster. Final most probable state accepted.&lt;/li&gt;
&lt;li&gt;However for more specific application labeling, cluster classification for at least the chief nodes needs to be manual.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Weiss' Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Similar to Hart's algorithm to measure and extract switching events in the dataset.&lt;/li&gt;
&lt;li&gt;Maps the &lt;strong&gt;Signature database&lt;/strong&gt; for predefined application categories defined to the event data.&lt;/li&gt;
&lt;li&gt;Uses real, active and distortion power to present a more 3 dimensional outlook.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supervised approach&lt;/strong&gt; in general.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Kolter's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Uses HMM's like Parson's algorithm but unsupervised still.&lt;/li&gt;
&lt;li&gt;Detects the &lt;em&gt;application cycle&lt;/em&gt; for ON OFF.&lt;/li&gt;
&lt;li&gt;Implements k-means clustering in order to find the centroid in a cluster of data points s.t. the distance to maximum points is minimized.&lt;/li&gt;
&lt;li&gt;Extension to implement the AFAMAP algorithm for further analysis.&lt;/li&gt;
&lt;li&gt;Obtains no. of applications and their respective consumption pattern.&lt;/li&gt;
&lt;li&gt;Done on the &lt;strong&gt;REDD&lt;/strong&gt; Dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;NILM Results on Algorithms and Conclusions&lt;/h2&gt;
&lt;h4&gt;Parson's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ECO Dataset scaled to 1/60 Hz (requirement of the algorithm).&lt;/li&gt;
&lt;li&gt;2 primary appliances, Fridge and Microwave.&lt;/li&gt;
&lt;li&gt;Using probable Markov state determination through Viterbi.&lt;/li&gt;
&lt;li&gt;Fridge and Freezer data comparison difficult.&lt;/li&gt;
&lt;li&gt;Household 6 most accurate with &lt;strong&gt;max(F1) = 0.91&lt;/strong&gt; for Fridge.&lt;/li&gt;
&lt;li&gt;Household 4 and 5 most accurate for Microwave.&lt;/li&gt;
&lt;li&gt;Due to data aggregation, 59/60 portions of data lost, leading to consumption patterns to differ considerably.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Baranski's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Segregation and clustering of dataset based on switching events with similar changes in power consumption.&lt;/li&gt;
&lt;li&gt;Finite State Machines (FSM) consists of many finite states which are interchangeable amongst each other. &lt;/li&gt;
&lt;li&gt;Classification of these clusters into FSMs based on grouping, which defines approximate application boundaries.&lt;/li&gt;
&lt;li&gt;Average classifications reached at. Fridge discarded in the FSM list owing to OFF periods in separate clusters.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Did not arrive at concrete comparable data&lt;/strong&gt; owing to different I/O for the algorithm.&lt;/li&gt;
&lt;li&gt;Final application labeling done manually based on the power consumption, number of switching events and variations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Weiss' Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Used supervised approach with 1 Hz dataset.&lt;/li&gt;
&lt;li&gt;Categorized into cooling appliances, high power consumption appliances and remaining others.&lt;/li&gt;
&lt;li&gt;Highly accurate for cooling appliances with F1 = 0.91 to 0.94&lt;/li&gt;
&lt;li&gt;Highly accurate for high power consumption appliances with similar F1. However many False negatives leading to low Recall values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overall successful in application modeling&lt;/strong&gt; through provided through signature database.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Kolter's Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Uses &lt;strong&gt;k-means clustering&lt;/strong&gt; to find centroid in cluster and approximates application entities over the dataset.&lt;/li&gt;
&lt;li&gt;Identifies clusters and data snippets before segregating data.&lt;/li&gt;
&lt;li&gt;However, based on the HMM approach, no individual application model construction close to the given consumption model.&lt;/li&gt;
&lt;li&gt;Future expansion suggested based on the &lt;strong&gt;AFAMAP algorithm&lt;/strong&gt; (no info found on the algorithm).&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;This proves that &lt;strong&gt;Supervised (or semi-supervised ) learning&lt;/strong&gt; was &lt;strong&gt;dominant&lt;/strong&gt; to obtain accurate 
results with high F1, PRC and REC values. &lt;strong&gt;Weiss' and Parson's&lt;/strong&gt; perform better on the ECO Dataset
and were more consistent with the results. With HMM usage, generic and application specific
model, Parson's approach is promising, but needs higher frequency data to obtain finer
results. Weiss potential and performance better than Parson due to same reason.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Some limitations that I saw with the framework was that too many constraints and configuration bindings. This leads to a more artificial simulation than real time load monitoring. Also, as it has been only done on the ECO Dataset, expansion to other sets is favorable.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Comparison with NILMTK in the next post...&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Mridul&lt;/em&gt;&lt;/h4&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mridul Malpotra</dc:creator><pubDate>Wed, 26 Nov 2014 21:25:00 +0100</pubDate><guid>tag:,2014-11-26:nilm-eval-and-eco-dataset.html</guid><category>nilm</category><category>nilm-eval</category><category>eco</category><category>algorithms</category><category>parson</category><category>weiss</category><category>baranski</category><category>kolter</category></item><item><title>ECO Converter - How it fared</title><link>/eco-converter-fared.html</link><description>&lt;p&gt;ECO Converter is being made at &lt;a href="https://github.com/mridulmalpotra/nilmtk/blob/master/nilmtk/dataset_converters/ECO"&gt;this repository.&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Few problems that were solved&lt;/h1&gt;
&lt;h3&gt;Problems: Memory Error and Slow Algorithm&lt;/h3&gt;
&lt;p&gt;As mentioned earlier, too much memory and too less resources were allocated. Some approaches to solving this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;As suggested by Nipun sir, I implemented an appending function to the existing HDF5file. Hence in this scenario, we would not merge the concatinated dataframe all at once but append it for every file. This made the speed of the program predictable, error-free and executed perfectly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This was also the time when I upgraded my laptop to a new one. Although I had to install and run nilmtk and its all dependencies from scratch, it made execution faster and I had more RAM and CPU speed to allot. This also helped in the process.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;&lt;em&gt;Mridul&lt;/em&gt;&lt;/h4&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mridul Malpotra</dc:creator><pubDate>Wed, 29 Oct 2014 01:27:00 +0100</pubDate><guid>tag:,2014-10-29:eco-converter-fared.html</guid><category>eco</category><category>converter</category><category>nilmtk</category><category>hdf5</category><category>memory</category><category>metadata</category></item><item><title>Problems with the ECO Converter</title><link>/problems-eco-converter.html</link><description>&lt;p&gt;ECO Converter is being made at &lt;a href="https://github.com/mridulmalpotra/nilmtk/blob/master/nilmtk/dataset_converters/ECO"&gt;this repository.&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Few problems as of now in the converter&lt;/h1&gt;
&lt;h2&gt;Problem 1: Memory Error&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Memory Error" src="../images/mem_error.png" /&gt;&lt;/p&gt;
&lt;p&gt;While implementing the dataset, the primary problem that I am facing is the large size of the dataset. The zipped files of the Smart meter readings were about 2.5 GB in size. This decompressed and added with a timestamp of &lt;em&gt;numpy.datetime64&lt;/em&gt; makes the file size large.&lt;/p&gt;
&lt;h3&gt;Dataset structure&lt;/h3&gt;
&lt;p&gt;ECO Dataset has folder 'i_sm_csv' and 'i_plug_csv' where i is the building no.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i_sm_csv has a folder i&lt;/li&gt;
&lt;li&gt;i_plug_csv has a folder 01, 02,....n where n are the plug numbers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each folder has a CSV file per day, with each file containing 86400 entries mapping every second of that day. Even for plug data which has a compressed zip size totalling 120 MB, owing to the 64-bit time stamp we get the hdf5file having a size &lt;em&gt;5-6 GB&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;The storage is even greater for a smart meter, making the final file large in size.&lt;/p&gt;
&lt;h3&gt;Low resources&lt;/h3&gt;
&lt;p&gt;My initial location for the HDF5file was a drive with probably not enough storage space as it encountered memory error quite easily. Doing the same in another disk partition with plenty space made the program last longer, but it freezes my system before completing even 1 smart_meter_csv. The CPU was becoming a throttle here as a single core is used 100%. Possible multithreading implementations could help, but cannot say with surety.&lt;/p&gt;
&lt;h2&gt;Problem 2: Slow Algorithm&lt;/h2&gt;
&lt;p&gt;My approach to calculating the dataframe for a meter is to initialize a dataframe and keep appending a dataframe per csv file. This means around 200-250 operations per meter per folder. This approach is linear and takes a long time for large data. As we are simply appending the dataframes together and sorting by index in the end, one clear method to speed up the process is using a divide and conquer approach and reduce the overall complexity to O(log(n)). This puts a lesser load on the CPU. If this will benefit the algorithm, I will implement it in the converter.&lt;/p&gt;
&lt;p&gt;However, the dataframe object created per meter becomes too huge for the smart meter computations. I will try to find some alternative for storing in the hdf5file.&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Mridul&lt;/em&gt;&lt;/h4&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mridul Malpotra</dc:creator><pubDate>Mon, 20 Oct 2014 11:21:00 +0200</pubDate><guid>tag:,2014-10-20:problems-eco-converter.html</guid><category>eco</category><category>converter</category><category>nilmtk</category><category>hdf5</category><category>memory</category><category>metadata</category></item></channel></rss>